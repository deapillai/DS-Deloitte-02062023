{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Pruning in Decision Trees - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will use the titanic dataset to see the impact of tree pruning and hyperparameter tuning on the predictive performance of a decision tree classifier. Pruning reduces the size of decision trees by removing nodes of the tree that do not provide much predictive power to classify instances. Decision trees are the most susceptible out of all the machine learning algorithms to overfitting and effective pruning can reduce this likelihood. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Determine the optimal hyperparameters for a decision tree model and evaluate the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "Let's first import the libraries you'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_872/3702245053.py:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "The titanic dataset, available in `'titanic.csv'`, is all cleaned up and preprocessed for you so that you can focus on pruning and optimization. Import the dataset and print the first five rows of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0            1  22.0      1      0   7.2500         0         0         1   \n",
      "1            2  38.0      1      0  71.2833         1         0         0   \n",
      "2            3  26.0      0      0   7.9250         0         0         1   \n",
      "3            4  35.0      1      0  53.1000         1         0         0   \n",
      "4            5  35.0      0      0   8.0500         0         0         1   \n",
      "\n",
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Survived  \n",
      "0           0         1           0           0           1         0  \n",
      "1           1         0           1           0           0         1  \n",
      "2           1         0           0           0           1         1  \n",
      "3           1         0           0           0           1         1  \n",
      "4           0         1           0           0           1         0  \n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('titanic.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets\n",
    "\n",
    "- Assign the `'Survived'` column to `y` \n",
    "- Drop the `'Survived'` and `'PassengerId'` columns from `df`, and assign the resulting DataFrame to `X` \n",
    "- Split `X` and `y` into training and test sets. Assign 30% to the test set and set the `random_state` to `SEED` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y \n",
    "y = df['Survived']\n",
    "X = X = df.drop(['Survived', 'PassengerId'], axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "SEED = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a vanilla classifier\n",
    "\n",
    "__Note:__ The term \"vanilla\" is used for a machine learning algorithm with its default settings (no tweaking/tuning).\n",
    "\n",
    "- Instantiate a decision tree \n",
    "  - Use the `'entropy'` criterion and set the `random_state` to `SEED` \n",
    "- Fit this classifier to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier using training data\n",
    "dt = clf = DecisionTreeClassifier(criterion='entropy', random_state=SEED)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions \n",
    "- Create a set of predictions using the test set \n",
    "- Using `y_test` and `y_pred`, calculate the AUC (Area under the curve) to check the predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check the AUC of predictions\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m false_positive_rate, true_positive_rate, thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m roc_auc\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Make predictions using test set \n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Check the AUC of predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = None\n",
    "roc_auc = None\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Tree Depth\n",
    "\n",
    "Let's first check for the best depth parameter for our decision tree: \n",
    "\n",
    "- Create an array for `max_depth` values ranging from 1 - 32  \n",
    "- In a loop, train the classifier for each depth value (32 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 6 (252999168.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [9], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    clf = DecisionTreeClassifier(max_depth=max_depth)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 6\n"
     ]
    }
   ],
   "source": [
    "# Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train_aucs = []\n",
    "test_aucs = []\n",
    "for  max_depth in max_depths:\n",
    "clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_train)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m(y_train, y_train_pred)\n\u001b[1;32m      5\u001b[0m test_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_test_pred)\n\u001b[1;32m      6\u001b[0m train_aucs\u001b[38;5;241m.\u001b[39mappend(train_auc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Your observations here \n",
    "y_train_pred = clf.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "train_aucs.append(train_auc)\n",
    "test_aucs.append(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Sample Split\n",
    "\n",
    "Now check for the best `min_samples_splits` parameter for our decision tree \n",
    "\n",
    "- Create an array for `min_sample_splits` values ranging from 0.1 - 1 with an increment of 0.1 \n",
    "- In a loop, train the classifier for each `min_samples_splits` value (10 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'min_samples_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m train_aucs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m test_aucs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[43mmin_samples_split\u001b[49m)\n\u001b[1;32m      9\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'min_samples_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Identify the optimal min-samples-split for given data\n",
    "min_samples_splits = np.arange(0.1, 1.1, 0.1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train_aucs = []\n",
    "test_aucs = []\n",
    "clf = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "train_score = roc_auc_score(y_train, y_train_pred)\n",
    "test_score = roc_auc_score(y_test, y_test_pred)\n",
    "train_scores.append(train_score)\n",
    "test_scores.append(test_score)\n",
    "train_aucs.append(np.mean(train_scores))\n",
    "test_aucs.append(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your observations here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_samples_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_aucs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain AUC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(min_samples_splits, test_aucs, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest AUC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/pyplot.py:2730\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your observations here\n",
    "plt.plot(min_samples_splits, train_aucs, label='Train AUC')\n",
    "plt.plot(min_samples_splits, test_aucs, label='Test AUC')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Sample Leafs\n",
    "\n",
    "Now check for the best `min_samples_leafs` parameter value for our decision tree \n",
    "\n",
    "- Create an array for `min_samples_leafs` values ranging from 0.1 - 0.5 with an increment of 0.1 \n",
    "- In a loop, train the classifier for each `min_samples_leafs` value (5 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m train_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m test_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX_train_all\u001b[49m, y_train_all, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      8\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(min_samples_leaf\u001b[38;5;241m=\u001b[39mmin_samples_leaf)\n\u001b[1;32m      9\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the optimal value for minimum sample leafs\n",
    "min_samples_leafs = np.arange(0.1, 0.6, 0.1)\n",
    "train_aucs = []\n",
    "test_aucs = []\n",
    "train_auc = 0\n",
    "test_auc = 0\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2)\n",
    "clf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict_proba(X_train)[:, 1]\n",
    "train_auc += roc_auc_score(y_train, y_pred_train)\n",
    "y_pred_test = clf.predict_proba(X_test)[:, 1]\n",
    "test_auc += roc_auc_score(y_test, y_pred_test)\n",
    "train_auc /= 5\n",
    "test_auc /= 5\n",
    "\n",
    "train_aucs.append(train_auc)\n",
    "test_aucs.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your observations here \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_samples_leafs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_aucs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain AUC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(min_samples_leafs, test_aucs, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest AUC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/pyplot.py:2730\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your observations here \n",
    "plt.plot(min_samples_leafs, train_aucs, label='train AUC')\n",
    "plt.plot(min_samples_leafs, test_aucs, label='test AUC')\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Features\n",
    "\n",
    "Now check for the best `max_features` parameter value for our decision tree \n",
    "\n",
    "- Create an array for `max_features` values ranging from 1 - 12 (1 feature vs all)\n",
    "- In a loop, train the classifier for each `max_features` value (12 runs) \n",
    "- Calculate the training and test AUC for each run \n",
    "- Plot a graph to show under/overfitting and the optimal value \n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the best value for optimal maximum feature size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m max_features_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m13\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdata, data\u001b[38;5;241m.\u001b[39mtarget, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m load(max_features)\n\u001b[1;32m      5\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the best value for optimal maximum feature size\n",
    "max_features_array = np.arange(1, 13)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "data = load(max_features)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=max_feat)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "train_scores.append(train_auc)\n",
    "test_scores.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your observations here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(max_features_array, \u001b[43mtrain_scores\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain AUC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(max_features_array, test_scores, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest AUC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# Your observations here\n",
    "plt.plot(max_features_array, train_scores, label='Train AUC')\n",
    "plt.plot(max_features_array, test_scores, label='Test AUC')\n",
    "plt.xlabel('Max Features')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train the classifier with chosen values\n",
    "\n",
    "Now we will use the best values from each training phase above and feed it back to our classifier. Then we can see if there is any improvement in predictive performance. \n",
    "\n",
    "- Train the classifier with the optimal values identified \n",
    "- Compare the AUC of the new model with the earlier vanilla decision tree AUC \n",
    "- Interpret the results of the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a classifier with optimal values identified above\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m false_positive_rate, true_positive_rate, thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m roc_auc\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Train a classifier with optimal values identified above\n",
    "dt = None\n",
    "\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = None\n",
    "roc_auc = None\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to address the issue of a baseline classifier performing better than a tuned one like this, a more-sophisticated technique is called a \"grid search\" and this will be introduced in a future lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we looked at tuning a decision tree classifier in order to avoid overfitting and increasing the generalization capabilities of the classifier. For the titanic dataset, we see that identifying optimal parameter values can result in some improvements towards predictions. This idea will be exploited further in upcoming lessons and labs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
