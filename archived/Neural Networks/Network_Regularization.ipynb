{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj-KeuZT7UYR",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    Objectives\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#When-a-Good-Model-Goes-Bad\" data-toc-modified-id=\"When-a-Good-Model-Goes-Bad-2\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    When a Good Model Goes Bad\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#Bias-Variance-Tradeoff\" data-toc-modified-id=\"Bias-Variance-Tradeoff-2.1\">\n",
    "                            <span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>\n",
    "                            Bias-Variance Tradeoff\n",
    "                        </a>\n",
    "                    </span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Underfitting\" data-toc-modified-id=\"Underfitting-2.1.1\">\n",
    "                                    <span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>\n",
    "                                    Underfitting\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-2.1.2\">\n",
    "                                    <span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>\n",
    "                                    Overfitting\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è\" data-toc-modified-id=\"How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è-2.2\">\n",
    "                            <span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>\n",
    "                            How Do We Identify a Bad Model? üïµÔ∏è\n",
    "                        </a>\n",
    "                    </span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Solution---Model-Validation\" data-toc-modified-id=\"Solution---Model-Validation-2.2.1\">\n",
    "                                    <span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>\n",
    "                                    Solution - Model Validation\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Steps:\" data-toc-modified-id=\"Steps:-2.2.2\">\n",
    "                                    <span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>\n",
    "                                    Steps:\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#The-Power-of-the-Validation-Set\" data-toc-modified-id=\"The-Power-of-the-Validation-Set-2.2.3\">\n",
    "                                    <span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>\n",
    "                                    The Power of the Validation Set\n",
    "                                </a>\n",
    "                            </span>\n",
    "                            <ul class=\"toc-item\">\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#From-Validation-to-Cross-Validation\" data-toc-modified-id=\"From-Validation-to-Cross-Validation-2.2.3.1\">\n",
    "                                            <span class=\"toc-item-num\">2.2.3.1&nbsp;&nbsp;</span>\n",
    "                                            From Validation to Cross-Validation\\\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#Preventing-Overfitting---Regularization\" data-toc-modified-id=\"Preventing-Overfitting---Regularization-3\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    Preventing Overfitting - Regularization\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net\" data-toc-modified-id=\"The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net-3.1\">\n",
    "                            <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>\n",
    "                            The Strategy Behind Ridge / Lasso / Elastic Net\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#Ridge-and-Lasso-Regression\" data-toc-modified-id=\"Ridge-and-Lasso-Regression-3.2\">\n",
    "                            <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>\n",
    "                            Ridge and Lasso Regression\n",
    "                        </a>\n",
    "                    </span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Lasso:-L1-Regularization---Absolute-Value\" data-toc-modified-id=\"Lasso:-L1-Regularization---Absolute-Value-3.2.1\">\n",
    "                                    <span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>\n",
    "                                    Lasso: L1 Regularization - Absolute Value\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Ridge:-L2-Regularization---Squared-Value\" data-toc-modified-id=\"Ridge:-L2-Regularization---Squared-Value-3.2.2\">\n",
    "                                    <span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>\n",
    "                                    Ridge: L2 Regularization - Squared Value\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#ü§î-Which-Do-I-Use?\" data-toc-modified-id=\"ü§î-Which-Do-I-Use?-3.2.3\">\n",
    "                                    <span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>\n",
    "                                    ü§î Which Do I Use?\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#The-Best-of-Both-Worlds:-Elastic-Net\" data-toc-modified-id=\"The-Best-of-Both-Worlds:-Elastic-Net-3.2.4\">\n",
    "                                    <span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>\n",
    "                                    The Best of Both Worlds: Elastic Net\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#Code-it-Out!\" data-toc-modified-id=\"Code-it-Out!-3.3\">\n",
    "                            <span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>\n",
    "                            Code it Out!\n",
    "                        </a>\n",
    "                    </span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Producing-an-Overfit-Model\" data-toc-modified-id=\"Producing-an-Overfit-Model-3.3.1\">\n",
    "                                    <span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>\n",
    "                                    Producing an Overfit Model\n",
    "                                </a>\n",
    "                            </span>\n",
    "                            <ul class=\"toc-item\">\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-3.3.1.1\">\n",
    "                                            <span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>\n",
    "                                            Train-Test Split\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#First-simple-model\" data-toc-modified-id=\"First-simple-model-3.3.1.2\">\n",
    "                                            <span class=\"toc-item-num\">3.3.1.2&nbsp;&nbsp;</span>\n",
    "                                            First simple model\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Add-Polynomial-Features\" data-toc-modified-id=\"Add-Polynomial-Features-3.3.1.3\">\n",
    "                                            <span class=\"toc-item-num\">3.3.1.3&nbsp;&nbsp;</span>\n",
    "                                            Add Polynomial Features\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Ridge-(L2)-Regression\" data-toc-modified-id=\"Ridge-(L2)-Regression-3.3.2\">\n",
    "                                    <span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>\n",
    "                                    Ridge (L2) Regression\n",
    "                                </a>\n",
    "                            </span>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Cross-Validation-to-Optimize-the-Regularization-Hyperparameter\" data-toc-modified-id=\"Cross-Validation-to-Optimize-the-Regularization-Hyperparameter-3.3.3\">\n",
    "                                    <span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>\n",
    "                                    Cross Validation to Optimize the Regularization Hyperparameter\n",
    "                                </a>\n",
    "                            </span>\n",
    "                            <ul class=\"toc-item\">\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Observation\" data-toc-modified-id=\"Observation-3.3.3.1\">\n",
    "                                            <span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>\n",
    "                                            Observation\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#Dropout-and-Early-Stopping\" data-toc-modified-id=\"Dropout-and-Early-Stopping-3.3.4\">\n",
    "                                    <span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>\n",
    "                                    Dropout and Early Stopping\n",
    "                                </a>\n",
    "                            </span>\n",
    "                            <ul class=\"toc-item\">\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Dropout\" data-toc-modified-id=\"Dropout-3.3.4.1\">\n",
    "                                            <span class=\"toc-item-num\">3.3.4.1&nbsp;&nbsp;</span>\n",
    "                                            Dropout\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Early-Stopping\" data-toc-modified-id=\"Early-Stopping-3.3.4.2\">\n",
    "                                            <span class=\"toc-item-num\">3.3.4.2&nbsp;&nbsp;</span>\n",
    "                                            Early Stopping\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                            <span>\n",
    "                                <a href=\"#LEVEL-UP---Elastic-Net!\" data-toc-modified-id=\"LEVEL-UP---Elastic-Net!-3.3.5\">\n",
    "                                    <span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>\n",
    "                                    LEVEL UP - Elastic Net!\n",
    "                                </a>\n",
    "                            </span>\n",
    "                            <ul class=\"toc-item\">\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Note-on-ElasticNet()\" data-toc-modified-id=\"Note-on-ElasticNet()-3.3.5.1\">\n",
    "                                            <span class=\"toc-item-num\">3.3.5.1&nbsp;&nbsp;</span>\n",
    "                                            Note on <code>ElasticNet()</code>\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                                <li>\n",
    "                                    <span>\n",
    "                                        <a href=\"#Fitting-Regularized-Models-with-Cross-Validation\" data-toc-modified-id=\"Fitting-Regularized-Models-with-Cross-Validation-3.3.5.2\">\n",
    "                                            <span class=\"toc-item-num\">3.3.5.2&nbsp;&nbsp;</span>\n",
    "                                            Fitting Regularized Models with Cross-Validation\n",
    "                                        </a>\n",
    "                                    </span>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAFPWazG7UYc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression,\\\n",
    "LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, KFold,\\\n",
    "cross_val_score, cross_validate, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Y8IjfEBH7UYd"
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xvZlZ5lc7UYd"
   },
   "source": [
    "- Elaborate on the notion of \"validation data\"\n",
    "- More practice using cross-validation\n",
    "- Explain the concept of regularization\n",
    "- Use Lasso and Ridge regularization in model design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "2WS_ZB0R7UYd"
   },
   "source": [
    "One of the goals of a machine learning project is to make models which are highly predictive.\n",
    "If the model fails to generalize to unseen data then the model is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "GvKzt_ct7UYd"
   },
   "source": [
    "# When a Good Model Goes Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "58hKTKlB7UYd"
   },
   "source": [
    "> One of the goals of a machine learning project is to make models which are highly predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "5_dbyATf7UYd"
   },
   "source": [
    "Adding complexity to a model can find patterns to help make better predictions! \n",
    "\n",
    "But too much complexity can lead to the model finding patterns in the noise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "raVCr4z47UYd"
   },
   "source": [
    "![Overfitting Model](https://media.tenor.com/9ppNC0UBHbUAAAAC/charlie-day-its-always-sunny-in-philadelphia.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "20sbEvVd7UYd"
   },
   "source": [
    ">So how do we know when our model is ~~a conspiracy theorist~~ overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MUAZq4Fl7UYd"
   },
   "source": [
    "## Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "cY_JyL8f7UYe"
   },
   "source": [
    "### High bias\n",
    "* Bias is about the strength of assumptions the model makes\n",
    "* Underfit models tend to have high bias; conversely, overfit models tend to have low bias\n",
    "* Systematic (irreducible) error in predictions\n",
    "\n",
    "### High variance\n",
    "* The model is highly sensitive to changes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "OshHO76S7UYe"
   },
   "source": [
    "> Bias and variance both impact a model's ability to generalize well\n",
    "\n",
    "![](https://miro.medium.com/max/562/1*RQ6ICt_FBSx6mkAsGVwx8g.png)\n",
    "\n",
    "[Source](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "vGB11eKs7UYe"
   },
   "source": [
    "##### Aside: Example of high bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "geUOi2QN7UYe"
   },
   "source": [
    "High bias is easy to wrap one's mind around: Imagine pulling three red balls from an urn that has hundreds of balls of all colors in a uniform distribution. Then my sample is a terrible representative of the whole population. If I were to build a model by extrapolating from my sample, that model would predict that _every_ ball produced would be red! That is, this model would be incredibly biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ai6w-V9q7UYe"
   },
   "source": [
    "High variance is a little bit harder to visualize, but it's basically the \"opposite\" of this. Imagine that the population of balls in the urn is mostly red, but also that there are a few balls of other colors floating around. Now imagine that our sample comprises a few balls, none of which is red. In this case, we've essentially picked up on the \"noise\", rather than the \"signal\". If I were to build a model by extrapolating from my sample, that model would be needlessly complex. It might predict that balls drawn before noon will be orange and that balls drawn after 8pm will be green, when the reality is that a simple model that predicted 'red' for all balls would be a superior model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "2Nr78GCt7UYe"
   },
   "source": [
    "The important idea here is that there is a *trade-off*: If we have too few data in our sample (training set), or too few predictors, we run the risk of high *bias*, i.e. an underfit model. On the other hand, if we have too many predictors (especially ones that are collinear), we run the risk of high *variance*, i.e. an overfit model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "arfQy0Fj7UYe"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/1920px-Overfitting.svg.png\" width = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8xn0oKn7UYe"
   },
   "source": [
    "> In general, a model with high variance is suggestive that it is overfit to the training data.\n",
    "Also, as model complexity increases, there is an increase in variance and a decrease in bias; whether MSE increases or decreases depends on the relative rate of change between these two factors -- the bias will tend to drop quickly (faster than the variance can increase), and test MSE will drop. Increased further, model complexity leads to a reduction in bias (because it fits the training data easily) and variance then rapidly increases, due to the model being overfit.\n",
    "\n",
    "Source: Advanced Algorithmic Trading, Michael Halls-Moore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "09kDdJua7UYe"
   },
   "source": [
    "### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8S58LHBO7UYe"
   },
   "source": [
    "> Underfit models fail to capture all of the information in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "7_IODQE-7UYe"
   },
   "source": [
    "* low complexity $\\rightarrow$ high bias, low variance\n",
    "* training error: large\n",
    "* testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "CdimFx1-7UYe"
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "GUt_Xeb57UYf"
   },
   "source": [
    "> Overfit models fit to the noise in the data and fail to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4hGW7cYp7UYf"
   },
   "source": [
    "* high complexity $\\rightarrow$ low bias, high variance\n",
    "* training error: low\n",
    "* testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbBlPSly7UYf"
   },
   "source": [
    "> **Simple models are preferred over complex models, by virtue of the fact that complex models overfit the training data and fail to generalize very well from previously-unseen data.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "2MhxVsKg7UYf"
   },
   "source": [
    "## How Do We Identify a Bad Model? üïµÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "QyKISddL7UYf"
   },
   "source": [
    "### Solution - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "dyNYJJDk7UYf"
   },
   "source": [
    "Generally speaking we want to take more precautions than using just a test and train split. After all, we're still imagining building just one model on the training set and then crossing our fingers for its performance on the test set.\n",
    "\n",
    "Data scientists often distinguish *three* subsets of data: **training, validation (dev), and testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9kJe-i9n7UYf"
   },
   "source": [
    "Roughly:\n",
    "- Training data is for building the model;\n",
    "- Validation data is for *tweaking* the model;\n",
    "- Testing data is for evaluating the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "A_potUj57UYf"
   },
   "source": [
    "- Think of **training** data as what you study for a test\n",
    "- Think of **validation** data is using a practice test (note sometimes called **dev**)\n",
    "- Think of **testing** data as what you use to judge the model\n",
    "    - A **holdout** set is when your test dataset is never used for training (unlike in cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "cwWey61c7UYf"
   },
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "> Image from Scikit-Learn https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "yuXz21t77UYf"
   },
   "source": [
    "### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WNIKRVAG7UYf"
   },
   "source": [
    "1. Split data into training data and a holdout test\n",
    "2. Design a model\n",
    "3. Evaluate how well it generalizes with **cross-validation** (only training data)\n",
    "4. Determine if we should adjust model, use cross-validation to evaluate, and repeat\n",
    "5. After iteratively adjusting your model, do a _final_ evaluation with the holdout test set\n",
    "6. DON'T TOUCH THE MODEL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "5m91EOT87UYf"
   },
   "source": [
    "### The Power of the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "rL_bcT4U7UYf"
   },
   "source": [
    "This \"tweaking\" includes most of all the fine-tuning of model parameters (see below). Think of what this three-way distinction allows us to do:\n",
    "\n",
    "I can build a model on some data. Then, **before** I introduce the model to the testing data, I can introduce it to a different batch of data (the validation set). With respect to the validation data I can do things like measure error and tweak model parameters to minimize that error. Of course, I also don't want to lose sight of the error on the training data. If the model error has been minimized on the training error, then of course any changes I make to the model parameters will take me away from that minimum. But still the new information I've gained by looking at the model's performance on the validation data is valuable. I might for example go with a kind of compromising model whose parameters produce an error that's not too big on the training data and not too big on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "EQyImfN57UYf"
   },
   "source": [
    "**Question**: What's different about this procedure from what we've described before? Aren't I just calling the test data \"validation data\" now? Is there any substantive difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "ks9Ixon17UYf"
   },
   "source": [
    "#### From Validation to Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8hR6elgh7UYf"
   },
   "source": [
    "Since my model will \"see\" the validation data in any case, I might as well use *all* of my training data to validate my model! How do I do this?\n",
    "\n",
    "Cross-validation works like this: First I'll partition my training data into $k$-many *folds*. Then I'll train a model on $k-1$ of those folds and \"test\" it on the remaining fold. I'll do this for all possible divisions of my $k$ folds into $k-1$ training folds and a single \"testing\" fold. Since there are $k\\choose 1$$=k$-many ways of doing this, I'll be building $k$-many models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "uzDVew1x7UYg"
   },
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fnb7X1eA7UYg"
   },
   "source": [
    "***For a really cool visualization of cross-validation behavior in `scikit-learn`, check out this notebook from the [`scikit-learn` docs](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html):***\n",
    "\n",
    "<br>\n",
    "<a href=\"https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.1.X?urlpath=lab/tree/notebooks/auto_examples/model_selection/plot_cv_indices.ipynb\">\n",
    "  <img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "tuRTau3V7UYg"
   },
   "source": [
    "##### A Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "hidden": true,
    "id": "2bTEEy4X7UYg",
    "outputId": "4394edc5-d640-4c3d-b068-0148d1d1ffff"
   },
   "outputs": [],
   "source": [
    "birds = sns.load_dataset('penguins')\n",
    "birds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "H3LwdKmL7UYg",
    "outputId": "46cfb311-10d3-4d7c-90b6-20a356b47b71"
   },
   "outputs": [],
   "source": [
    "birds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0-crGkCe7UYg"
   },
   "outputs": [],
   "source": [
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "# Newer versions of seaborn have \"bill\" instead of \"culmen\".\n",
    "\n",
    "numeric = birds[['bill_length_mm', 'bill_depth_mm',\n",
    "                 'flipper_length_mm', 'body_mass_g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "HsSRviGJ7UYg"
   },
   "outputs": [],
   "source": [
    "# We'll drop the rows with null values\n",
    "\n",
    "numeric = numeric.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pgzrJExO7UYg"
   },
   "source": [
    "Suppose I want to model `body_mass_g` as a function of the other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "D1QV91lL7UYg"
   },
   "outputs": [],
   "source": [
    "X = numeric.drop('body_mass_g', axis=1)\n",
    "y = numeric['body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "q7_L_Z2_7UYh"
   },
   "source": [
    "We'll make ten models and record our evaluations of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "9q70eWXE7UYh"
   },
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "s2qmP5rk7UYh"
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X, \n",
    "                y=y,\n",
    "                estimator=lr2, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "R-E40SAo7UYh",
    "outputId": "05d56eec-30a3-4bf4-9180-90a5ed796966"
   },
   "outputs": [],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbEqj0cM7UYh",
    "outputId": "c98e0fe6-7167-4b2a-d4f6-509c0372984f"
   },
   "outputs": [],
   "source": [
    "cv_results.get('train_r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "UZkUWHr67UYh",
    "outputId": "8c97e05c-95e6-4894-fb1b-ccdb4f961cdc"
   },
   "outputs": [],
   "source": [
    "cv_results.get('test_r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "8SDEI9en7UYh",
    "outputId": "696fe160-6c5b-4b01-c0d0-c22a84785c51"
   },
   "outputs": [],
   "source": [
    "# Compare the results\n",
    "print(-1*cv_results.get('train_neg_mean_squared_error').mean(),\n",
    "      cv_results.get('train_neg_mean_squared_error').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "eiiFh1K47UYh",
    "outputId": "f715e023-c9fd-416a-d6bb-b57776978ee8"
   },
   "outputs": [],
   "source": [
    "print(-1*cv_results.get('test_neg_mean_squared_error').mean(),\n",
    "      cv_results.get('test_neg_mean_squared_error').std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "EFILKN6M7UYh"
   },
   "source": [
    "# Preventing Overfitting - Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "IvuYmUWA7UYh"
   },
   "source": [
    "Again, complex models are very flexible in the patterns that they can model but this also means that they can easily find patterns that are simply statistical flukes of one particular dataset rather than patterns reflective of the underlying data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "RGSU1lU67UYh"
   },
   "source": [
    "When a model has large weights, the model is \"too confident\". This translates to a model with high variance which puts it in danger of overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "rY1E0J_I7UYh"
   },
   "source": [
    "![](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6uYLOUfy7UYh"
   },
   "source": [
    "We need to punish large (confident) weights by contributing them to the error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "5EqAiOE27UYi"
   },
   "source": [
    "**Some Types of Regularization:**\n",
    "\n",
    "1. Reducing the number of features\n",
    "2. Increasing the amount of data\n",
    "3. Popular techniques: Ridge, Lasso, Elastic Net, Dropout\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Hwd7Ndur7UYi"
   },
   "source": [
    "## The Strategy Behind Ridge / Lasso / Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FTnYEPFL7UYi"
   },
   "source": [
    "Overfit models overestimate the relevance that predictors have for a target. Thus overfit models tend to have **overly large coefficients**. \n",
    "\n",
    "Generally, overfitting models come from a result of high model variance. High model variance can be caused by:\n",
    "\n",
    "- having irrelevant or too many predictors\n",
    "- multicollinearity\n",
    "- large coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "zyAKSMT-7UYi"
   },
   "source": [
    "The evaluation of many models, linear regression included, proceeds by measuring its **error**, some quantifiable expression of the discrepancy between its predictions and the ground truth. The best-fit line of LR, for example, minimizes the sum of squared residuals.\n",
    "\n",
    "Our new idea, then, will be ***to add a term representing the size of our coefficients to our loss function***. This will be our **cost function** $J$.\n",
    "\n",
    "The goal will still be to minimize this new function, but we can make progress toward this minimum *either* by reducing the size of our residuals *or* by reducing the size of our coefficients.\n",
    "\n",
    "Since coefficients can be either negative or positive, we have the familiar difficulty that we can't simply add them up to get a sense of how large they are in general. Once again there are two natural choices: We could focus either on the squares or the absolute values of the coefficients. The former strategy is the basis for **Ridge** (also called Tikhonov) regularization; the latter strategy results in **Lasso** (Least Absolute Shrinkage and Selection Operator) regularization.\n",
    "\n",
    "These tools, as we shall see, are easily implemented with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "yLeaYs6H7UYi"
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ttlmENO87UYi"
   },
   "source": [
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by _penalizing_ the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "blE3DwzI7UYi"
   },
   "source": [
    "## Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "3wgjXh_n7UYi"
   },
   "source": [
    "The first problem is about picking up on noise rather than signal.\n",
    "The second problem is about having a least-squares estimate that is highly sensitive to random error.\n",
    "The third is about having highly sensitive predictors.\n",
    "\n",
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by penalizing the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "vpSmEd-f7UYi"
   },
   "source": [
    "### Lasso: L1 Regularization - Absolute Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ga3bRBxK7UYi"
   },
   "source": [
    "- \"Regularization for Sparcity\" ([source](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization#l1-vs.-l2-regularizationhttps://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization#l1-vs.-l2-regularization.))\n",
    "- Tend to get sparse vectors (small weights go to 0)\n",
    "- Reduce number of weights\n",
    "- Good feature selection to pick out importance\n",
    "\n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\lambda|w_i| \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "PEtNzRfH7UYi"
   },
   "source": [
    "### Ridge: L2 Regularization - Squared Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "81KTQT997UYi"
   },
   "source": [
    "- \"Regularization for Simplicity\" ([source](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization))\n",
    "- Not sparse vectors (weights homogeneous & small)\n",
    "- Tends to give better results for training\n",
    "\n",
    "    \n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\lambda w_i^2 \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "goNiLMTR7UYi"
   },
   "source": [
    "### ü§î Which Do I Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "D_ThPpaZ7UYi"
   },
   "source": [
    "> Typically you'll want to use L2 regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "gW_ihWmj7UYi"
   },
   "source": [
    "- For a given value of $\\lambda$ ([more on lambda](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda)), the ridge makes for a gentler reining in of runaway coefficients. When in doubt, try ridge first.\n",
    "- The lasso will more quickly reduce the contribution of individual predictors down to insignificance. It is therefore most useful for trimming through the fat of datasets with many predictors or if a model with very few predictors is especially desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "BxNFzlxB7UYi"
   },
   "source": [
    "##### Aside: Comparing L1 & L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "PPnetv9Z7UYi"
   },
   "source": [
    "This is a bit subtle: \n",
    "- Consider vectors: [1,0] & [0.5, 0.5] \n",
    "- Recall we want smallest value for our value\n",
    "- L2 prefers [0.5,0.5] over [1,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "iPEDaArr7UYi"
   },
   "source": [
    "### The Best of Both Worlds: Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "P559KWng7UYj"
   },
   "source": [
    "There is a combination of L1 and L2 regularization called the Elastic Net that can also be used. The idea is to use a scaled linear combination of the lasso and the ridge, where the weights add up to 100%. We might want 50% of each, but we also might want, say, 10% Lasso and 90% Ridge.\n",
    "\n",
    "The loss function for an Elastic Net Regression looks like this:\n",
    "\n",
    "Elastic Net:\n",
    "\n",
    "$\\rho\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}|\\beta_j|] + (1 - \\rho)\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}\\beta^2_j]$\n",
    "\n",
    "Sometimes you will see this loss function represented with different scaling terms, but the basic idea is to have a combination of L1 and L2 regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "K1Lyrjjd7UYj"
   },
   "source": [
    "## Code it Out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "_wPYvXVL7UYj"
   },
   "source": [
    "### Producing an Overfit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DbXnrm3S7UYj"
   },
   "source": [
    "We can often produce an overfit model by including **interaction terms**. We'll start over with the penguins dataset. This time we'll include the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "N9QXXFlI7UYj"
   },
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "sX0Qplmb7UYj"
   },
   "outputs": [],
   "source": [
    "birds = sns.load_dataset('penguins')\n",
    "birds = birds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "hidden": true,
    "id": "yOC6nKkp7UYj",
    "outputId": "bb6f9bbc-fc38-4c25-cd2b-fecbbc4f1afe"
   },
   "outputs": [],
   "source": [
    "birds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UNxTrmwv7UYj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        birds.drop('body_mass_g', axis=1),\n",
    "                                        birds['body_mass_g'],\n",
    "                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "hidden": true,
    "id": "RxGU6AZ27UYj",
    "outputId": "29c0964b-35b2-429d-81ed-fe60100f0f48"
   },
   "outputs": [],
   "source": [
    "# Taking in other features (category)\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "\n",
    "# Getting a DF\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "\n",
    "# What we'll feed int our model\n",
    "X_train_df = pd.concat([X_train[['bill_length_mm', 'bill_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "vi6MLZ_k7UYj"
   },
   "source": [
    "Our Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "GSUY3xQG7UYj",
    "outputId": "1d0745fb-a9fb-42b4-c949-43a0a4256da3"
   },
   "outputs": [],
   "source": [
    "# Note the same transformation (not FIT) to match structure\n",
    "test_dummies = ohe.transform(X_test[['species', 'island', 'sex']])\n",
    "test_df = pd.DataFrame(test_dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                       index=X_test.index)\n",
    "X_test_df = pd.concat([X_test[['bill_length_mm', 'bill_depth_mm',\n",
    "                              'flipper_length_mm']], test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Cm_teuw07UYj"
   },
   "source": [
    "#### First simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "esUsaFVE7UYj",
    "outputId": "a11143f3-3a68-43ee-e3df-e9c52ddd19f5"
   },
   "outputs": [],
   "source": [
    "lr1 = LinearRegression()\n",
    "lr1.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "vBC6vAnF7UYk",
    "outputId": "fd6b0766-1e0d-4f64-ece9-c57ec1f6f0d1"
   },
   "outputs": [],
   "source": [
    "lr1.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "AkB_q1q37UYk"
   },
   "source": [
    "Let's do some cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "xjWKHFpC7UYk"
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_train_df, \n",
    "                y=y_train,\n",
    "                estimator=lr1, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Bv-5kk-U7UYk",
    "outputId": "f71acefc-a2b4-4219-aa17-1e686a1e85cc"
   },
   "outputs": [],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "ZDJdEkwn7UYk",
    "outputId": "7ff6bc91-ed0f-4598-db3b-4edf60004da2"
   },
   "outputs": [],
   "source": [
    "train_res = cv_results['train_r2']\n",
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Ol0Tqw_o7UYk",
    "outputId": "ffb79828-60cf-4767-b5ca-5e9b0bb856f6"
   },
   "outputs": [],
   "source": [
    "valid_res = cv_results['test_r2']\n",
    "valid_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "kevfcQQp7UYk"
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "u6-Qol-u7UYk"
   },
   "outputs": [],
   "source": [
    "pens_preds = lr1.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "-0CFh4nP7UYk",
    "outputId": "07534e28-4cfa-49a5-a2fd-bbd3933e4cf2"
   },
   "outputs": [],
   "source": [
    "lr1.score(X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "qAZxgvcG7UYk",
    "outputId": "5874664e-59e8-4957-cbac-c7cf3cb988f2"
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(pens_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "CzbyUXSA7UYk"
   },
   "source": [
    "#### Add Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2ygCmbn37UYk"
   },
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=3)\n",
    "X_poly_train = pf.fit_transform(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "9NciiVGM7UYk"
   },
   "outputs": [],
   "source": [
    "X_poly_test = pf.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "TPsLrauI7UYk"
   },
   "source": [
    "Train the model and evaluate (with cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Dl-zfwnT7UYk",
    "outputId": "dee8115d-bc7d-4c1b-d561-10a76eae2989"
   },
   "outputs": [],
   "source": [
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_poly_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "nn-IqRKS7UYk",
    "outputId": "2720c779-60dd-47a9-ac70-36c877548e51"
   },
   "outputs": [],
   "source": [
    "poly_lr.score(X_poly_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "wRE1oeqO7UYl"
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_poly_train, \n",
    "                y=y_train,\n",
    "                estimator=poly_lr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "YRyfS_7G7UYl",
    "outputId": "aa880c53-1af0-41c3-f071-7432bcea7d9e"
   },
   "outputs": [],
   "source": [
    "train_res = cv_results['train_r2']\n",
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "iL3mklho7UYl",
    "outputId": "4a7837c1-ed19-43e1-8506-05f02f20ce0f"
   },
   "outputs": [],
   "source": [
    "valid_res = cv_results['test_r2']\n",
    "valid_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "erS43xkY7UYl"
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "jPZGg5fd7UYl",
    "outputId": "6290d48f-3fa2-47ea-ff4e-740ab637d0c8"
   },
   "outputs": [],
   "source": [
    "poly_lr.score(X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "AL80-Xwf7UYl"
   },
   "outputs": [],
   "source": [
    "poly_preds = poly_lr.predict(X_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "JmnVC12x7UYl",
    "outputId": "347fe7a2-bd40-4a40-e9b6-3d9168c44201"
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(poly_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "j80hBoJs7UYl"
   },
   "source": [
    "### Ridge (L2) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XMKA19FH7UYl"
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# You should always be sure to _standardize_ your data before\n",
    "# applying regularization!\n",
    "\n",
    "X_train_processed = pf.fit_transform(ss.fit_transform(X_train_df))\n",
    "X_test_processed = pf.transform(ss.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCHdGarM2y78"
   },
   "source": [
    "**Note: Lasso(alpha=0) is equivalent to the normal linear regression solved by the LinearRegression() class. It is not advised to use alpha=0 with Lasso regression. Instead, you should use normal linear regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "KwBa3BGf7UYl",
    "outputId": "28df4dfc-a199-41da-c3dd-d89a542ae621"
   },
   "outputs": [],
   "source": [
    "# 'Lambda' is the standard variable for the strength of the\n",
    "# regularization (as in the above formulas), but since lambda\n",
    "# is a key word in Python, these sklearn regularization tools\n",
    "# use 'alpha' instead.\n",
    "\n",
    "rr = Ridge(alpha=100, random_state=42)\n",
    "\n",
    "rr.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "yXJC7rZz7UYl",
    "outputId": "6a61b4ed-f749-423f-bd47-bd2c1333c4ee"
   },
   "outputs": [],
   "source": [
    "rr.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "kPTG3qUm7UYl"
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_train_processed, \n",
    "                y=y_train,\n",
    "                estimator=rr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "F4fnbyN37UYl",
    "outputId": "ec77476c-cea2-44b3-ca0d-512dace49139"
   },
   "outputs": [],
   "source": [
    "cv_results['train_r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "NHunZ7YL7UYl",
    "outputId": "b3bb5926-3a60-42bf-b22e-9c7cbb63abb5"
   },
   "outputs": [],
   "source": [
    "cv_results['test_r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "ak-L8wxQ7UYl"
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "gNhDoIWi7UYm"
   },
   "outputs": [],
   "source": [
    "ridge_preds = rr.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "ts1tUgC47UYm",
    "outputId": "33dff843-e067-45ef-c943-be5d7c836e25",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr.score(X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Cuw_yfHE7UYm",
    "outputId": "0b102d49-4599-4a46-e274-d6f7a5545825"
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(ridge_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "d-VZhhgw7UYm"
   },
   "source": [
    "Much better! But how do we know which value of `alpha` to pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "J-n-89Yw7UYm"
   },
   "source": [
    "### Optimizing the Regularization Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aI2ObRg-7UYm"
   },
   "source": [
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OnB3GHjp7UYm"
   },
   "outputs": [],
   "source": [
    "alphas = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10_000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    rr.fit(X_train_processed, y_train)\n",
    "    train_score = rr.score(X_train_processed, y_train)\n",
    "    test_score = rr.score(X_test_processed, y_test)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "hidden": true,
    "id": "vO9vLixM7UYm",
    "outputId": "6287d65e-ddd6-4b1d-aab2-5cd79aae6bf3"
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "dyHZzSK87UYm"
   },
   "source": [
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "GOX0yzmh7UYm"
   },
   "source": [
    "Notice how the values increase but then decrease? Regularization helps with overfitting, but if the strength of the regularization becomes too great, then large coefficients will be punished more than they really should. What happens then is that the original error between truth and model predictions becomes neglected as a quantity to be minimized, and the bias of the model begins to outweigh its variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Qv5X99EI7UYm"
   },
   "source": [
    "It looks like the best value is somewhere around 100. If we wanted more precision, we could repeat the same sort of exercise with a set of alphas nearer to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaFhN92s7UYm"
   },
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuDDx-uk7UYm",
    "outputId": "f5496a80-d992-4705-dc43-0c9958695574"
   },
   "outputs": [],
   "source": [
    "alphas = [1e-3, 1e-2, 1e-1, 1]\n",
    "cv_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    cv_results = cross_validate(\n",
    "                X=X_train_df, \n",
    "                y=y_train,\n",
    "                estimator=rr, \n",
    "                cv=10,\n",
    "                scoring=('neg_mean_squared_error'))\n",
    "    cv_scores.append(-np.median(cv_results['test_score']))\n",
    "\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "sQt5Ptwl7UYm",
    "outputId": "151d046e-72cf-4a4c-a538-e25921faa506"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge MSE as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.plot(alphas, cv_scores, label='cross-validated')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOX-Gdl27UYm"
   },
   "source": [
    "### Dropout and Early Stopping\n",
    "\n",
    "Does regularization make sense in the context of neural networks?\n",
    "\n",
    "Yes! We still have all of the salient ingredients: a loss function, overfitting vs. underfitting, and coefficients (weights) that could get too large.\n",
    "\n",
    "But there are now a few different flavors besides L1 and L2 regularization.\n",
    "\n",
    "Note: a downside of using L1 regularization is that the technique can‚Äôt be easily used with some ML training algorithms, in particular those algorithms that use calculus to compute what‚Äôs called a gradient [(source)](https://learn.microsoft.com/en-us/archive/msdn-magazine/2015/february/test-run-l1-and-l2-regularization-for-machine-learning).\n",
    "\n",
    "We'll add a few more layers to give regularization a better chance of making a difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no4k4q8w7UYm"
   },
   "source": [
    "#### Dropout [(original paper)](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "\n",
    "One popular model regularization technique involves specifying a dropout layer in Keras, which randomly shuts off different nodes during training. This can help to prevent overfitting and is illustrated below:\n",
    "\n",
    "![drop_out](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/04/1IrdJ5PghD9YoOyVAQ73MJw.gif)\n",
    "\n",
    "> With unlimited computation, the best way to ‚Äúregularize‚Äù a fixed-sized model is to average the predictions of all possible settings of the parameters, weighting each setting by its posterior probability given the training data. This can sometimes be approximated quite well for simple or small models (Xiong et al., 2011; Salakhutdinov and Mnih, 2008), but we would like to approach the performance of the Bayesian gold standard using considerably less computation. We propose to do this by approximating an equally weighted geometric mean of the predictions of an exponential number of learned models that share parameters.\n",
    "\n",
    "To add dropout to a keras network, simply add it as though it were a layer. It will apply to the immediately preceding layer (see the `Dropout` section of the `Level Up: Regularization` content from the [previous lecture material](https://github.com/flatiron-school/DS-Deloitte-02062023/blob/main/Neural%20Networks/Network_Evaluation_and_Normalization.ipynb)).\n",
    "\n",
    "<!-- <br>\n",
    "<a href=\"https://colab.research.google.com/drive/1GohskX91cw3p6ysYt63zWk8KB73bgS9p#scrollTo=fBbkcNYe10Pu\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tHzEaAG7UYn"
   },
   "source": [
    "#### Early Stopping\n",
    "\n",
    "Another technique is to stop training when a monitored metric has stopped improving.\n",
    "\n",
    "The working assumption is that the goal of model training is to minimize the loss. With this, the metric to be monitored would be `'loss'`, and mode would be `'min'`. A `model.fit()` training loop will check at end of every epoch whether the loss is no longer decreasing, considering the provided values for the `min_delta` and `patience` arguments. Once it's found to no longer be decreasing, `model.stop_training` is marked `True` and model training terminates.\n",
    "\n",
    "See the [Keras docs](https://keras.io/api/callbacks/early_stopping/) for more info -- and feel free to try it out for yourself (see the `Early Stopping` section of the `Level Up: Regularization` content from the [previous lecture material](https://github.com/flatiron-school/DS-Deloitte-02062023/blob/main/Neural%20Networks/Network_Evaluation_and_Normalization.ipynb)).\n",
    "\n",
    "<!-- <br>\n",
    "<a href=\"https://colab.research.google.com/drive/1GohskX91cw3p6ysYt63zWk8KB73bgS9p#scrollTo=yDoj2osu10Pu\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a> -->\n",
    "\n",
    "![](https://peltarion.com/static/early_stopping_pa2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "oN3KdTpo7UYn"
   },
   "source": [
    "### LEVEL UP - Elastic Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "HKk5tPIO7UYn"
   },
   "source": [
    "Naturally, the Elastic Net has the same interface through sklearn as the other regularization tools! The only difference is that we now have to specify how much of each regularization term we want. The name of the parameter for this (represented by $\\rho$ above) in sklearn is `l1_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "m0x-X3ID7UYn",
    "outputId": "0459a66f-098e-49e9-e559-d86da854b296"
   },
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=10, l1_ratio=0.1, random_state=42)\n",
    "\n",
    "enet.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "xUXww1qt7UYn",
    "outputId": "1e1257df-cce1-4c6f-b40d-0e5b8d5a2e36"
   },
   "outputs": [],
   "source": [
    "enet.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "uyOqRiTE7UYn",
    "outputId": "0cc29348-3bb3-435c-b442-7e78d45e754e"
   },
   "outputs": [],
   "source": [
    "enet.score(X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "YsFHq7Ji7UYn"
   },
   "source": [
    "Setting the `l1_ratio` to 1 is equivalent to the lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tfFpPTi27UYn"
   },
   "outputs": [],
   "source": [
    "ratios = np.linspace(0.01, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Q-VVGwHU7UYn"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for ratio in ratios:\n",
    "    enet = ElasticNet(alpha=100, l1_ratio=ratio, random_state=42)\n",
    "    enet.fit(X_train_processed, y_train)\n",
    "    preds.append(enet.predict(X_test_processed[0].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "hidden": true,
    "id": "foqJEnqH7UYn",
    "outputId": "716113b8-46d7-48fa-95fb-afa6e5847115"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "lasso = Lasso(alpha=100, random_state=42)\n",
    "lasso.fit(X_train_processed, y_train)\n",
    "lasso_pred = lasso.predict(X_test_processed[0].reshape(1, -1))\n",
    "\n",
    "ax.plot(ratios, preds, label='elastic net')\n",
    "ax.scatter(1, lasso_pred, c='k', s=70, label='lasso')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "9tf4R4n37UYn"
   },
   "source": [
    "#### Note on `ElasticNet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6hzeJ1W07UYn"
   },
   "source": [
    "Is an Elastic Net with `l1_ratio` set to 0 equivalent to the ridge? In theory yes. But in practice no. It looks like the `ElasticNet()` predictions on the first test data point as `l1_ratio` shrinks are tending toward some value around 3400. Let's check to see what prediction `Ridge()` gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "czbfqhVD7UYn",
    "outputId": "6b2090f1-6bbb-4d87-c71b-f916082880ad"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10, random_state=42)\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "ridge.predict(X_test_processed[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Agb2OAi67UYn"
   },
   "source": [
    "If you check the docstring for the `ElasticNet()` class you will see:\n",
    "- that the function being minimized is slightly different from what we saw above; and\n",
    "- that the results are unreliable when `l1_ratio` $\\leq 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "YzpSJt6n7UYn"
   },
   "source": [
    "**Exercise**: Visualize the difference in this case between `ElasticNet(l1_ratio=0.01)` and `Ridge()` by making a scatterplot of each model's predicted values for the first ten points in `X_test_processed`. Use `alpha=10` for each model.\n",
    "\n",
    "        Level Up: Make a second scatterplot that compares the predictions on the same data\n",
    "        points between ElasticNet(l1_ratio=1) and Lasso()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WLOTnInk7UYn"
   },
   "source": [
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    <code>fig, ax = plt.subplots()\n",
    "enet_r = ElasticNet(alpha=10, l1_ratio=0.01, random_state=42)\n",
    "enet_r.fit(X_train_processed, y_train)\n",
    "preds_enr = enet_r.predict(X_test_processed[:10])\n",
    "preds_ridge = ridge.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enr)\n",
    "ax.scatter(np.arange(10), preds_ridge);</code>  \n",
    "        </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "HmC3rHtM7UYn"
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Level Up\n",
    "    </summary>\n",
    "<code>fig, ax = plt.subplots()\n",
    "enet_l = ElasticNet(alpha=10, l1_ratio=1, random_state=42)\n",
    "enet_l.fit(X_train_processed, y_train)\n",
    "preds_enl = enet_l.predict(X_test_processed[:10])\n",
    "preds_lasso = lasso.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enl)\n",
    "ax.scatter(np.arange(10), preds_lasso);</code>\n",
    "    </details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "TDZShQul7UYo",
    "outputId": "dde97084-dd58-468f-b104-522c6380b4e0"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "enet_r = ElasticNet(alpha=10, l1_ratio=0.01, random_state=42)\n",
    "enet_r.fit(X_train_processed, y_train)\n",
    "preds_enr = enet_r.predict(X_test_processed[:10])\n",
    "preds_ridge = ridge.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enr)\n",
    "ax.scatter(np.arange(10), preds_ridge);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "7Ux4_-6f7UYo",
    "outputId": "ab3a36de-f617-48d1-f979-145ec81453cb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "enet_l = ElasticNet(alpha=10, l1_ratio=1, random_state=42)\n",
    "enet_l.fit(X_train_processed, y_train)\n",
    "preds_enl = enet_l.predict(X_test_processed[:10])\n",
    "preds_lasso = lasso.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enl)\n",
    "ax.scatter(np.arange(10), preds_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bt5fKGm37UYo"
   },
   "source": [
    "#### Fitting Regularized Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "v78uXrrV7UYo"
   },
   "source": [
    "Our friend `sklearn` also includes tools that fit regularized regressions *with cross-validation*: `LassoCV`, `RidgeCV`, and `ElasticNetCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6TnzFWjg7UYo"
   },
   "source": [
    "**Exercise**: Use `RidgeCV` to fit a seven-fold cross-validated ridge regression model to our `X_train_processed` data and then calculate $R^2$ and the RMSE (root-mean-squared error) on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8PiAOGE7UYo",
    "outputId": "bf6b52fd-cae5-47a2-ed7f-2f83a90404d0"
   },
   "outputs": [],
   "source": [
    "rcv = RidgeCV(cv=7)\n",
    "rcv.fit(X_train_processed, y_train)\n",
    "rcv.score(X_test_processed, y_test)\n",
    "np.sqrt(mean_squared_error(y_test, rcv.predict(X_test_processed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DVXr_FkO7UYo"
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Answer\n",
    "    </summary>\n",
    "    <code>rcv = RidgeCV(cv=7)\n",
    "rcv.fit(X_train_processed, y_train)\n",
    "rcv.score(X_test_processed, y_test)\n",
    "np.sqrt(mean_squared_error(y_test, rcv.predict(X_test_processed)))</code>\n",
    "    </details>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "no4k4q8w7UYm",
    "2tHzEaAG7UYn"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "47px",
    "left": "46px",
    "top": "175px",
    "width": "286px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
