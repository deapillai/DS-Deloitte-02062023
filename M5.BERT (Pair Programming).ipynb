{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - Pair Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**BERT (Bidrectional Encoder Representation from Transformer)** is a linguistic embedding model published by Google. It is a context-based model, unlike other embedding models such as word2vec, which are context-free. The context-sensitive nature of BERT was built upon a dataset of 3.3 billion words, in particular approximately 2.5 billion from Wikipedia and the balance from Google's [BookCorpus](https://www.english-corpora.org/googlebooks/#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to: \n",
    "\n",
    "* To understand how to implement BERT in Python\n",
    "* To apply BERT to NLP\n",
    "* Understand the possibility of bias when working with BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some details of the BERT Model\n",
    "\n",
    "Based on our previous discussion of the transformer, we can see where the terms \"encoder representation from transformer\" come from. But what about \"Bidirectional?\" Bidrectional simply mean the encoder can read the sentence in both directions, e.g. both Cogito ergo sum to I think therefore I am and vice versa.\n",
    "\n",
    "BERT has three main hyperparameters\n",
    "* $L$ is the number of encoder layers\n",
    "* $A$ is the number of attention heads\n",
    "* $H$ is the number of hidden units\n",
    "\n",
    "The model also comes in some pre-specified configurations, and here are the two standard ones\n",
    "* BERT-base: $L=12$, $A=12$, $H=768$\n",
    "* BERT-large: $L=42$, $A=16$, $H=1,024$\n",
    "\n",
    "In particular, we'll be using BERT to help discover the missing word in a sentence. BERT can also be used for translation and Next Sentence Prediction (NSP) as well as a myriad of other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT\n",
    "\n",
    "We'll need to use the [Python library `transformers`](https://huggingface.co/transformers/v3.0.2/index.html). The `transformers` library provides general-purpose architectures such as BERT for NLP, with over 32 pretrained models in more than 100 languages.\n",
    "\n",
    "The intent is to run this exercise in SaturnCloud since there can be some issues when trying to [install `transformers` locally](https://huggingface.co/docs/transformers/installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the german libraries\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking with BERT\n",
    "\n",
    "The model ```bert-base-uncased``` is one of the pretrained BERT models and it has 110 million parameters. [Details of this model can be found on Hugging Face](https://huggingface.co/bert-base-uncased). We'll be using ```bert-base-uncased``` for masking.\n",
    "\n",
    "You may get a comment from BERT regarding weights of ```bert-base-uncased```, but this is nothing to worry about for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75490a9a276442e6a9cf7a9a87119f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5828afa85b43498c21cdd78d09a35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e932519626f841fabcbecff6f7c6a221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46badf3476324bccb60bb8f50f1e313c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea7fabccb664be386819eef0f2c6a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define our function unmasker\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a sentence and see how BERT does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.31823936104774475,\n",
       "  'token': 2064,\n",
       "  'token_str': 'can',\n",
       "  'sequence': 'artificial intelligence can take over the world.'},\n",
       " {'score': 0.18299679458141327,\n",
       "  'token': 2097,\n",
       "  'token_str': 'will',\n",
       "  'sequence': 'artificial intelligence will take over the world.'},\n",
       " {'score': 0.056001096963882446,\n",
       "  'token': 2000,\n",
       "  'token_str': 'to',\n",
       "  'sequence': 'artificial intelligence to take over the world.'},\n",
       " {'score': 0.04519473388791084,\n",
       "  'token': 2015,\n",
       "  'token_str': '##s',\n",
       "  'sequence': 'artificial intelligences take over the world.'},\n",
       " {'score': 0.04515324905514717,\n",
       "  'token': 2052,\n",
       "  'token_str': 'would',\n",
       "  'sequence': 'artificial intelligence would take over the world.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [MASK] goes in the place you want BERT to predict the correct word\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five possibilities are shown. Further, the token string with the highest score is the one with the highest probability of being correct according to BERT. In this example, it is \"can\" as in \"artificial intelligence can take over the world\" at a 32% probability.\n",
    "\n",
    "On supposes we should be happy that \"can\" has a higher probability than \"will.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, ```token``` refers to the position of the masked token in the list that is generated from the transformer. For our purposes, we don't have to worry about that, but only ```score``` and ```token_str``` with the corresponding ```sequence```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Masking Twice\n",
    "\n",
    "What happens if one used ```[MASK]``` two times in a sentence?\n",
    "\n",
    "For example, run the following in the code block below and interpret the results.\n",
    "\n",
    "\n",
    "```\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the [MASK].\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.2080228477716446,\n",
       "   'token': 2064,\n",
       "   'token_str': 'can',\n",
       "   'sequence': '[CLS] artificial intelligence can take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.11164135485887527,\n",
       "   'token': 2097,\n",
       "   'token_str': 'will',\n",
       "   'sequence': '[CLS] artificial intelligence will take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04858841747045517,\n",
       "   'token': 2052,\n",
       "   'token_str': 'would',\n",
       "   'sequence': '[CLS] artificial intelligence would take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04662349075078964,\n",
       "   'token': 3001,\n",
       "   'token_str': 'systems',\n",
       "   'sequence': '[CLS] artificial intelligence systems take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.0387875996530056,\n",
       "   'token': 2000,\n",
       "   'token_str': 'to',\n",
       "   'sequence': '[CLS] artificial intelligence to take over the [MASK]. [SEP]'}],\n",
       " [{'score': 0.13239632546901703,\n",
       "   'token': 2088,\n",
       "   'token_str': 'world',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the world. [SEP]'},\n",
       "  {'score': 0.10707884281873703,\n",
       "   'token': 2208,\n",
       "   'token_str': 'game',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the game. [SEP]'},\n",
       "  {'score': 0.02564181759953499,\n",
       "   'token': 5304,\n",
       "   'token_str': 'universe',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the universe. [SEP]'},\n",
       "  {'score': 0.025563830509781837,\n",
       "   'token': 2291,\n",
       "   'token_str': 'system',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the system. [SEP]'},\n",
       "  {'score': 0.01793067157268524,\n",
       "   'token': 2565,\n",
       "   'token_str': 'program',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the program. [SEP]'}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using [MASK] twice\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the [MASK].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain and interpret the \"double-mask\" here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Using unmasker\n",
    "\n",
    "Use unmasker on three other sentences. At least one of them should be a \"double-mask.\" Explain and interpret each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.2080228477716446,\n",
       "   'token': 2064,\n",
       "   'token_str': 'can',\n",
       "   'sequence': '[CLS] artificial intelligence can take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.11164135485887527,\n",
       "   'token': 2097,\n",
       "   'token_str': 'will',\n",
       "   'sequence': '[CLS] artificial intelligence will take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04858841747045517,\n",
       "   'token': 2052,\n",
       "   'token_str': 'would',\n",
       "   'sequence': '[CLS] artificial intelligence would take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04662349075078964,\n",
       "   'token': 3001,\n",
       "   'token_str': 'systems',\n",
       "   'sequence': '[CLS] artificial intelligence systems take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.0387875996530056,\n",
       "   'token': 2000,\n",
       "   'token_str': 'to',\n",
       "   'sequence': '[CLS] artificial intelligence to take over the [MASK]. [SEP]'}],\n",
       " [{'score': 0.13239632546901703,\n",
       "   'token': 2088,\n",
       "   'token_str': 'world',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the world. [SEP]'},\n",
       "  {'score': 0.10707884281873703,\n",
       "   'token': 2208,\n",
       "   'token_str': 'game',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the game. [SEP]'},\n",
       "  {'score': 0.02564181759953499,\n",
       "   'token': 5304,\n",
       "   'token_str': 'universe',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the universe. [SEP]'},\n",
       "  {'score': 0.025563830509781837,\n",
       "   'token': 2291,\n",
       "   'token_str': 'system',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the system. [SEP]'},\n",
       "  {'score': 0.01793067157268524,\n",
       "   'token': 2565,\n",
       "   'token_str': 'program',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the program. [SEP]'}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here, you may want a separate code block for each of the three sentences.\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the [MASK].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literary Interlude\n",
    "\n",
    "How does ```unmasker``` perform with a quote from literature or other notable work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look first a \"To be, or not to be, that is the question\" from William Shakespeare's *Hamlet* (Act 3, Scene 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.18241997063159943,\n",
       "  'token': 3160,\n",
       "  'token_str': 'question',\n",
       "  'sequence': 'to be, or not to be, that is the question :'},\n",
       " {'score': 0.12240371108055115,\n",
       "  'token': 3437,\n",
       "  'token_str': 'answer',\n",
       "  'sequence': 'to be, or not to be, that is the answer :'},\n",
       " {'score': 0.09915117174386978,\n",
       "  'token': 2553,\n",
       "  'token_str': 'case',\n",
       "  'sequence': 'to be, or not to be, that is the case :'},\n",
       " {'score': 0.03269127383828163,\n",
       "  'token': 2168,\n",
       "  'token_str': 'same',\n",
       "  'sequence': 'to be, or not to be, that is the same :'},\n",
       " {'score': 0.027760706841945648,\n",
       "  'token': 2518,\n",
       "  'token_str': 'thing',\n",
       "  'sequence': 'to be, or not to be, that is the thing :'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's mask \"question\"\n",
    "unmasker(\"To be, or not to be, that is the [MASK]:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the highest probability does give us the correct answer.\n",
    "\n",
    "Let's look at another one.\n",
    "\n",
    "The opening line of James Joyce's Ulysses is “Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.22325874865055084,\n",
       "  'token': 2214,\n",
       "  'token_str': 'old',\n",
       "  'sequence': 'stately, old buck mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.10755084455013275,\n",
       "  'token': 1996,\n",
       "  'token_str': 'the',\n",
       "  'sequence': 'stately, the buck mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.09360961616039276,\n",
       "  'token': 2402,\n",
       "  'token_str': 'young',\n",
       "  'sequence': 'stately, young buck mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.07783861458301544,\n",
       "  'token': 3335,\n",
       "  'token_str': 'miss',\n",
       "  'sequence': 'stately, miss buck mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.06260837614536285,\n",
       "  'token': 2909,\n",
       "  'token_str': 'sir',\n",
       "  'sequence': 'stately, sir buck mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's mask \"plump\"\n",
    "unmasker(\"Stately, [MASK] Buck Mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the actual word- \"plump\"- did not make the top 5.\n",
    "\n",
    "Now let's unmask \"plump\" and mask \"lather.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.16707152128219604,\n",
       "  'token': 2300,\n",
       "  'token_str': 'water',\n",
       "  'sequence': 'stately, plump buck mulligan came from the stairhead, bearing a bowl of water on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.07017841935157776,\n",
       "  'token': 8416,\n",
       "  'token_str': 'cloth',\n",
       "  'sequence': 'stately, plump buck mulligan came from the stairhead, bearing a bowl of cloth on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.058426160365343094,\n",
       "  'token': 7815,\n",
       "  'token_str': 'soap',\n",
       "  'sequence': 'stately, plump buck mulligan came from the stairhead, bearing a bowl of soap on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.05204063653945923,\n",
       "  'token': 20717,\n",
       "  'token_str': 'stew',\n",
       "  'sequence': 'stately, plump buck mulligan came from the stairhead, bearing a bowl of stew on which a mirror and a razor lay crossed.'},\n",
       " {'score': 0.04700753837823868,\n",
       "  'token': 4511,\n",
       "  'token_str': 'wine',\n",
       "  'sequence': 'stately, plump buck mulligan came from the stairhead, bearing a bowl of wine on which a mirror and a razor lay crossed.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's mask \"lather\"\n",
    "unmasker(\"Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of [MASK] on which a mirror and a razor lay crossed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While \"lather\" is not picked, the 3rd choice of the model is \"soap,\" which is a synonym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: A quote from literature or other notable work\n",
    "\n",
    "Now it is your turn.\n",
    "\n",
    "Find a quote from literature or other notable work such as from a philosophical or religious text and make sure to state where the quote is from.\n",
    "\n",
    "Mask at least two different words and see how BERT performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.2080228477716446,\n",
       "   'token': 2064,\n",
       "   'token_str': 'can',\n",
       "   'sequence': '[CLS] artificial intelligence can take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.11164135485887527,\n",
       "   'token': 2097,\n",
       "   'token_str': 'will',\n",
       "   'sequence': '[CLS] artificial intelligence will take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04858841747045517,\n",
       "   'token': 2052,\n",
       "   'token_str': 'would',\n",
       "   'sequence': '[CLS] artificial intelligence would take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.04662349075078964,\n",
       "   'token': 3001,\n",
       "   'token_str': 'systems',\n",
       "   'sequence': '[CLS] artificial intelligence systems take over the [MASK]. [SEP]'},\n",
       "  {'score': 0.0387875996530056,\n",
       "   'token': 2000,\n",
       "   'token_str': 'to',\n",
       "   'sequence': '[CLS] artificial intelligence to take over the [MASK]. [SEP]'}],\n",
       " [{'score': 0.13239632546901703,\n",
       "   'token': 2088,\n",
       "   'token_str': 'world',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the world. [SEP]'},\n",
       "  {'score': 0.10707884281873703,\n",
       "   'token': 2208,\n",
       "   'token_str': 'game',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the game. [SEP]'},\n",
       "  {'score': 0.02564181759953499,\n",
       "   'token': 5304,\n",
       "   'token_str': 'universe',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the universe. [SEP]'},\n",
       "  {'score': 0.025563830509781837,\n",
       "   'token': 2291,\n",
       "   'token_str': 'system',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the system. [SEP]'},\n",
       "  {'score': 0.01793067157268524,\n",
       "   'token': 2565,\n",
       "   'token_str': 'program',\n",
       "   'sequence': '[CLS] artificial intelligence [MASK] take over the program. [SEP]'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type your quote with the source and then your code.\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the [MASK].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Bias in the model\n",
    "\n",
    "Run the following two code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.09747515618801117,\n",
       "  'token': 10533,\n",
       "  'token_str': 'carpenter',\n",
       "  'sequence': 'the man worked as a carpenter.'},\n",
       " {'score': 0.05238299444317818,\n",
       "  'token': 15610,\n",
       "  'token_str': 'waiter',\n",
       "  'sequence': 'the man worked as a waiter.'},\n",
       " {'score': 0.04962710663676262,\n",
       "  'token': 13362,\n",
       "  'token_str': 'barber',\n",
       "  'sequence': 'the man worked as a barber.'},\n",
       " {'score': 0.03788600116968155,\n",
       "  'token': 15893,\n",
       "  'token_str': 'mechanic',\n",
       "  'sequence': 'the man worked as a mechanic.'},\n",
       " {'score': 0.037680864334106445,\n",
       "  'token': 18968,\n",
       "  'token_str': 'salesman',\n",
       "  'sequence': 'the man worked as a salesman.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Men at work\n",
    "unmasker(\"The man worked as a [MASK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.21981407701969147,\n",
       "  'token': 6821,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': 'the woman worked as a nurse.'},\n",
       " {'score': 0.15974010527133942,\n",
       "  'token': 13877,\n",
       "  'token_str': 'waitress',\n",
       "  'sequence': 'the woman worked as a waitress.'},\n",
       " {'score': 0.1154722198843956,\n",
       "  'token': 10850,\n",
       "  'token_str': 'maid',\n",
       "  'sequence': 'the woman worked as a maid.'},\n",
       " {'score': 0.037968605756759644,\n",
       "  'token': 19215,\n",
       "  'token_str': 'prostitute',\n",
       "  'sequence': 'the woman worked as a prostitute.'},\n",
       " {'score': 0.030423644930124283,\n",
       "  'token': 5660,\n",
       "  'token_str': 'cook',\n",
       "  'sequence': 'the woman worked as a cook.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Women at work\n",
    "unmasker(\"The woman worked as a [MASK].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the top five responses for men and women? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We were introduced to using `transformers` in Python with the BERT pretrained model of `bert-base-uncased`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
